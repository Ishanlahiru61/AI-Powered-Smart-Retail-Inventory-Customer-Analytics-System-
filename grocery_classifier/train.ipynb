{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b9733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Tuner not installed, will train with default parameters\n",
      "Found 397 images belonging to 5 classes.\n",
      "Found 84 images belonging to 5 classes.\n",
      "Class weights: {0: np.float64(0.9452380952380952), 1: np.float64(0.9452380952380952), 2: np.float64(0.7561904761904762), 3: np.float64(1.2806451612903227), 4: np.float64(1.2806451612903227)}\n",
      "Training with default parameters...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishanlahiru/miniforge3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 195ms/step - accuracy: 0.3526 - loss: 1.5698 - val_accuracy: 0.6071 - val_loss: 1.1972\n",
      "Epoch 2/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.6574 - loss: 1.0995 - val_accuracy: 0.8929 - val_loss: 0.7908\n",
      "Epoch 3/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 162ms/step - accuracy: 0.8086 - loss: 0.7708 - val_accuracy: 0.9643 - val_loss: 0.5188\n",
      "Epoch 4/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.8741 - loss: 0.5627 - val_accuracy: 1.0000 - val_loss: 0.3346\n",
      "Epoch 5/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 164ms/step - accuracy: 0.9295 - loss: 0.4191 - val_accuracy: 1.0000 - val_loss: 0.2395\n",
      "Epoch 6/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9496 - loss: 0.3132 - val_accuracy: 1.0000 - val_loss: 0.1603\n",
      "Epoch 7/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 165ms/step - accuracy: 0.9471 - loss: 0.2742 - val_accuracy: 1.0000 - val_loss: 0.1242\n",
      "Epoch 8/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - accuracy: 0.9622 - loss: 0.2233 - val_accuracy: 1.0000 - val_loss: 0.0890\n",
      "Epoch 9/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9773 - loss: 0.1629 - val_accuracy: 1.0000 - val_loss: 0.0733\n",
      "Epoch 10/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.9723 - loss: 0.1625 - val_accuracy: 1.0000 - val_loss: 0.0572\n",
      "Epoch 11/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 187ms/step - accuracy: 0.9698 - loss: 0.1421 - val_accuracy: 1.0000 - val_loss: 0.0491\n",
      "Epoch 12/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9924 - loss: 0.0948 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
      "Epoch 13/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 185ms/step - accuracy: 0.9874 - loss: 0.1104 - val_accuracy: 1.0000 - val_loss: 0.0327\n",
      "Epoch 14/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.9950 - loss: 0.0848 - val_accuracy: 1.0000 - val_loss: 0.0280\n",
      "Epoch 15/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.9874 - loss: 0.0807 - val_accuracy: 1.0000 - val_loss: 0.0242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to /Users/ishanlahiru/Documents/grocery_classifier/dataset/best_grocery_model.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "try:\n",
    "    from kerastuner.tuners import RandomSearch\n",
    "    USE_TUNER = True\n",
    "except ImportError:\n",
    "    USE_TUNER = False\n",
    "    print(\"Keras Tuner not installed, will train with default parameters\")\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/ishanlahiru/Documents/grocery_classifier/dataset\"  \n",
    "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(BASE_DIR, \"validation\")\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 5\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "y_train = train_generator.classes  \n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "\n",
    "def build_model(hp=None):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "   \n",
    "    if hp:\n",
    "        x = Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1))(x)\n",
    "        x = Dense(hp.Int('dense_units', 64, 256, step=64), activation='relu')(x)\n",
    "        lr = hp.Choice('learning_rate', [1e-3, 1e-4, 1e-5])\n",
    "    else:\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        lr = LEARNING_RATE\n",
    "\n",
    "    output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "if USE_TUNER:\n",
    "    print(\"Using Keras Tuner for hyperparameter search...\")\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='tuner_dir',\n",
    "        project_name='grocery_cnn'\n",
    "    )\n",
    "\n",
    "    tuner.search(train_generator, validation_data=val_generator, epochs=10, class_weight=class_weights)\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "else:\n",
    "    print(\"Training with default parameters...\")\n",
    "    best_model = build_model()\n",
    "    best_model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_generator,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"best_grocery_model.h5\")\n",
    "best_model.save(MODEL_PATH)\n",
    "print(f\" Model saved to {MODEL_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
